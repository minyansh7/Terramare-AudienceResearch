{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARVftHgffsE6"
   },
   "source": [
    "## Section 1. Reddit Data Scrape## \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-Dapb2coqCfA",
    "outputId": "161d55e9-7bad-4f44-8b8d-8e47a3ae7003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ› ï¸ Install dependencies\n",
    "!pip install praw pandas\n",
    "\n",
    "import praw\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5HuTg_LpYBU"
   },
   "outputs": [],
   "source": [
    "# prompt: set Reddit_Client_ID\n",
    "# Reddit_Secret in secrets, how to read it in colab\n",
    "\n",
    "from google.colab import userdata\n",
    "reddit_client_id = userdata.get('Reddit_Client_ID')\n",
    "reddit_secret = userdata.get('Reddit_Secret')\n",
    "user_agent = 'd-listening/0.1'\n",
    "\n",
    "# Suppress PRAW's async environment warning\n",
    "logging.getLogger(\"praw\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-b5GJGh2dJE",
    "outputId": "b5aac323-6528-4c9d-a5e7-85d5df7fd509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Scraped 2977 AU-relevant items mentioning meditation (target: 5000):\n",
      "\n",
      "   type   subreddit                author  score  \\\n",
      "0  post  Meditation          Anima_Monday      2   \n",
      "1  post  Meditation           FunnyOWL007      7   \n",
      "2  post  Meditation           kikemeister      2   \n",
      "3  post  Meditation              TinaTeng      9   \n",
      "4  post  Meditation                sidgat      8   \n",
      "5  post  Meditation  Intrepid_Strike_2454      2   \n",
      "6  post  Meditation    ExperienceMany4417     35   \n",
      "7  post  Meditation         EthanGisclair      6   \n",
      "8  post  Meditation        AnnualPath9528      5   \n",
      "9  post  Meditation         Teastainedeye      8   \n",
      "\n",
      "                                                                                                       title  \\\n",
      "0                                                 Equanimity and Non-Attachment Meditation, A Novel Approach   \n",
      "1                                       I didnâ€™t think meditation could help the planetâ€¦ until I tried this.   \n",
      "2                                                                                          One negative take   \n",
      "3               I finally found something that helped me stick with meditation (after failing so many times)   \n",
      "4                                                                         The Value Of Meditation: Slow Down   \n",
      "5                                                                      Losing Presence, Losing Meditativness   \n",
      "6                                                        The more I meditate the less I want to go to school   \n",
      "7                                                              Iâ€™m 19 and Iâ€™ve had my deepest meditation yet   \n",
      "8  How does meditation supposedly help people realize a deeper consciousness according to some philosophies?   \n",
      "9                                                                                  How to learn TM for free?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                  This practice uses phrases for equanimity and non-attachment in a similar way to the ones for popular forms of metta bhavana (loving kindness) meditation.\\n\\nI developed this specific form that I am sharing here myself and am being transparent about this, so you can see it as a novel approach. Popular metta practice has phrases that one repeats as part of the process, such as 'may all beings be well'. Below are phrases for equanimity and non-attachment. This is just a possible way to approach it, one way to put the mind in the mode of equanimity and non-attachment, so that this state can then be abided in directly. You can try it out if you are interested. I am just passing on something which has been helpful for me as perhaps it may help others too.\\n\\nYou can mentally say the phrases, with the first part of each phrase being on the in-breath, and the second part (the 'fine') being on the out-breath. Doing this while breathing naturally, meaning not deliberately controlling the breath. Try it with eyes closed, and then if you wish, you can experiment with eyes open on some occasions to integrate it into the sense experience and make it gradually more available 'off the mat'.\\n\\nSo mentally saying these phrases while in the relative stillness and safety of a meditation posture, either sitting or lying down, and syncing it to the breathing:\\n\\n\"If it comes ... fine\\n\\nIf it doesn't come ... fine\\n\\nIf it changes ... fine\\n\\nIf it doesn't change ... fine\\n\\nIf it goes ... fine\\n\\nIf it doesn't go ... fine\"\\n\\nYou meditate like this until there is a natural sense of equanimity and non-attachment, a natural letting go into that, which might occur after only doing it once through, or it might take a bit longer with more repetitions. It puts the mind closer in attitude to the nature unconditional awareness which is the deeper reality of oneself. A letting go occurs and you more naturally abide in/as this unconditional awareness.\\n\\nDo the phrases at least once through, and then repeat as needed. When the phrases seem like they are no longer needed, then allow them to cease and then abide naturally as you are. If they become needed again at any point, then you can repeat them again, or just the ones that are needed as appropriate.   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I came across this article about the Sattva meditation app and its â€œ10 Days, One Treeâ€ campaign and honestly, it hit differently.\\n\\nLately, Iâ€™ve been feeling overwhelmed by the constant news about climate change. Itâ€™s easy to feel powerless in the face of such a massive issue. \\n\\nI downloaded the app out of curiosity (to top it, itâ€™s free )and because Iâ€™ve been meaning to get back into my meditation practice(fell off the wagon). But what I didnâ€™t expect was how satisfying it felt to know that something as quiet and personal as meditation could ripple out into something as tangible as planting a tree.\\n\\nMost climate initiatives either feel too overwhelming or too abstract. But this? It feels doable. Real. Like a tiny habit that helps both my stress levels and the planet.\\n\\nIt reminded me that change doesnâ€™t always have to be loud or dramatic. Sometimes itâ€™s just about showing up consistently for yourself and the planet.\\n\\nCurious if anyone else has tried it or found other apps/projects like this that link inner well-being with real-world impact.\\n   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I know there has been a few posts about articles with negative sentiment but wonder about your take given no overwhelming medical research. Hereâ€™s the latest. \\nPersonally, I think it has made more attuned over years but maybe also more emotional.  There could be of course other factors. I like the feeling after meditating.    \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Hey everyone,\\nI wanted to share something thatâ€™s been surprisingly helpful for meâ€”not as a â€œpro tip,â€ but just as a fellow struggler.\\n\\nFor years, I tried meditation apps, guided meditations, ASMR, breathing exercisesâ€¦ but honestly, I could never stick with it. My mind wouldnâ€™t sit still, I got frustrated, and eventually Iâ€™d give up.\\n\\nRecently, though, I stumbled onto something so simple Iâ€™m almost embarrassed: using a small, textured bracelet as a tactile anchor. Instead of fighting my racing mind, I just let my fingers quietly move bead by bead. It gave my hands something to do and my mind something to follow, without screens, without pressure.\\n\\nThis tiny ritual has helped me slow down, breathe better, and surprisinglyâ€”keep coming back to meditation, even on tough days.\\n\\nIâ€™m curious:\\nHas anyone else here tried adding a small physical element to their meditation practice? Did it help you stay more consistent or focused?\\nWould love to hear whatâ€™s worked (or not worked) for others!   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           My daily mindfulness meditation practice, 30min a day, has taught me an incredibly valuable skill..\\n\\nSlow down.\\n\\nI used to rush everything, want everything now, try to do too much in a short space of time, try to work all day, try to fix my whole life in a week, no consistency or repetition...I'd quit anything if I didn't see immediate results...\\n\\nAll good intentions but a terrible mindset/strategy that led to poor execution.\\n\\nMy mindfulness practice has taught me that, paradoxically, I get more out of life by slowing down, steadying myself, controlling myself so that I can focus on laying each and every brick...carefully, consistently, persistently...\\n\\nSlow progress is still progress...as long as I'm headed in the direction everything falls in place.\\n\\nThe tortoise from Aesops fable won the race because he was slow and steady...he persisted..he didn't run ahead and take a nap...he plodded along diligently and won.\\n\\nYour mindfulness practice will train you in this incredibly valuable skill in our tiktok minded generation everything is instant, fast and easy.\\n\\nNamaste. ðŸ™ðŸ»   \n",
      "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Hi everyone!  \\nI always find a new miracle method that helps me stay present almost continuously. Sometimes continuous breath awareness works, sometimes intermittent fasting during the day works wondersâ€”I can remain in a state of presence all day and even meditate during almost any activity. When I sit down and close my eyes, meditation happens almost effortlessly. During the day, when emotions and feelings arise, I can feel them, and they pass through smoothly. There is a distance between us.\\n\\nBut then something happens, and the daytime fasting is no longer as effective. Even if I manage to maintain breath awareness, it doesnâ€™t work as well anymoreâ€”it doesnâ€™t bring me back to the present. I get lost in my thoughts again, usually thoughts related to how I feel physically or emotionally. At those times, a tightening sensation usually appears in the center of my chestâ€”an emotional pain that activates all kinds of nonsense: regret over past things, worry about the future.\\n\\nThen I try to sit and allow it to be there, or allow it to move through my whole body. I try to just observe my breath, but I simply cannot find my way back to the present. Sometimes only physical exercise helpsâ€”a tough workout. But sometimes not even that.\\n\\nI want to remain in presence permanently. Having already spent so much â€œtimeâ€ in it, it feels even more painful when I canâ€™t be present. Somehow, I want to stay in presence nowâ€”these fluctuations are exhausting. Losing presence is painful.  \\nDoes anyone have any helpful or forward-looking ideas about this?   \n",
      "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The more I meditate the less I want to go to school\\n\\n\\nHi, Iâ€™m 17F and started meditating about 8 months ago. Over the past couple of months, Iâ€™ve really begun to notice the positive effects itâ€™s had on me, I feel much more connected to myself and the world around me.\\n\\nIâ€™m in my final year of school, and Iâ€™ve been struggling to stay focused on assignments and complete them. A lot of the work doesnâ€™t interest me or feel aligned with who I truly am, but I know I donâ€™t have a choice, I need to finish school, and I want to do well.\\n\\nDoes anyone have advice on how to stay motivated and disciplined when the work feels so uninspiring? Is it just a case of â€œsuck it up and push throughâ€?\\n\\nIâ€™ve been wondering if I could use meditation to help with my schoolwork in some way.\\n\\nAny advice would be appreciated, even if itâ€™s just someone telling me to tough it out. Itâ€™s only one more year so I guess itâ€™s really a small part of my life in the grand scheme of things.\\n\\nThank you!    \n",
      "7  Iâ€™ve been diving deeper into non-dual spirituality over the past two years or so, and itâ€™s been wonderful. The people whoâ€™ve had the biggest impact on me are Eckhart Tolle, Wayne Dyer, and Michael Singer. Naturally, The Power of Now and The Untethered Soul have been huge for me. (also The Shift, the movie, by Wayne Dyer is on youtube and is beautiful)\\n\\nOne of the biggest shifts Iâ€™ve noticed is how much more in tune Iâ€™ve become with the energy in my bodyâ€”especially when I get caught up in anxious or negative thinking. I can actually feel that energetic tension as it arises now. But more importantly, Iâ€™ve gotten much better at becoming aware of it, accepting it completely, and letting it pass without resistance.\\n\\nYesterday during meditation, I got really caught in some intense thoughts about past experiences. The emotional energy that came up was super strongâ€”but I very gently accepted it just as it was, simply seeing it before thought comes to label or judge. And then it felt like my whole body wrapped itself around the feeling, like an inner hug. The energy then completely dissolved. Then I saw at the top of my head a kind of void. Then for the next few moments I saw every thought that tried to arise just get pulled into that void and vanished before it could even fully form. I donâ€™t mean a void in a bad sense because I saw it as really helpful; it was pulling me into complete stillness.\\n\\nThen I saw the void open up into more depth and I saw this sort of orbâ€”it looked like it contained every thought/mental noise Iâ€™ve ever had or ever could have and it was all swirling around and stuff. That orb then zoomed out into this vast 3D grid of infinite space and disappeared completely. And just like that, my entire self-conceptâ€”everything I thought I was or any thought itself was gone. Like dust. I genuinely felt my entire existence as a human being fade into that infinite field.\\n\\nIâ€™ve learned a lot conceptually about the egoâ€™s insignificance and pure illusory nature, but this was by far my clearest, most direct experience of that. In that space, there was no thought at allâ€”just stillness. Infinite depth. And yet I was completely conscious and aware. So I just stayed there for a while.\\n\\nWhen I came out, I allowed that nice void to come back suck up any mental chatter before a concrete thought/judgement/worry could even form. Today was a great day. If I wasnâ€™t present with what I was doing or I was lost in thought, I remembered that void and itâ€™s just like everything in my head immediately returns to complete stillness and Iâ€™m brought back to presence.   \n",
      "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Meditation, in many philosophies, is seen as a gentle unraveling of the layers that cloud our true nature. It's not about becoming something new, but about remembering what has always been â€” a pure awareness untouched by thought, fear, or ego. By sitting in stillness and observing without judgment, one begins to detach from the endless chatter of the mind and experience the silent presence beneath it. Over time, this presence reveals itself not as something separate, but as the very essence of being â€” vast, unchanging, and deeply connected to all life. In this state, many describe a sense of unity, clarity, and peace that feels more real than anything grasped through the senses.\\n   \n",
      "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Iâ€™m interested in trying a TM practice after watching some David Lynch, but when I looked up the nearest center, they want an outrageous fee for four lessons. Thereâ€™s no way Iâ€™d pay for it, having gone to multiple Vipassana retreats where you are given food, a bed, shower, and optional one on one consultation for 10 DAYS without any required upfront fee. Vipassana only ask for an optional donation and operates worldwide by donations and volunteers.\\n\\nI donâ€™t get it. What is so technical or complicated about TM that it requires special enrollment? Meditation in my understanding should be natural and simple, and free as in beer to all people. Furthermore Iâ€™m not even clear on what one gets from four days of TM class, other than an assigned mantra? I mean you just sit quietly, focus on your breathing and recite a mantra. Right?\\n\\nAny links to alternative ways to learn it for free or an explanation of why TM is not a scam would be appreciated.   \n",
      "\n",
      "  matched_terms  \\\n",
      "0         [act]   \n",
      "1         [act]   \n",
      "2         [act]   \n",
      "3         [act]   \n",
      "4         [act]   \n",
      "5         [act]   \n",
      "6    [vic, uni]   \n",
      "7         [act]   \n",
      "8         [uni]   \n",
      "9         [act]   \n",
      "\n",
      "                                                                                                 url  \\\n",
      "0  https://reddit.com/r/Meditation/comments/1l3o2jc/equanimity_and_nonattachment_meditation_a_novel/   \n",
      "1   https://reddit.com/r/Meditation/comments/1l3nwf4/i_didnt_think_meditation_could_help_the_planet/   \n",
      "2                                https://reddit.com/r/Meditation/comments/1l3ls4c/one_negative_take/   \n",
      "3   https://reddit.com/r/Meditation/comments/1l3lj3v/i_finally_found_something_that_helped_me_stick/   \n",
      "4                https://reddit.com/r/Meditation/comments/1l3e8g9/the_value_of_meditation_slow_down/   \n",
      "5             https://reddit.com/r/Meditation/comments/1l3cowz/losing_presence_losing_meditativness/   \n",
      "6     https://reddit.com/r/Meditation/comments/1l2zdn0/the_more_i_meditate_the_less_i_want_to_go_to/   \n",
      "7      https://reddit.com/r/Meditation/comments/1l2w8bh/im_19_and_ive_had_my_deepest_meditation_yet/   \n",
      "8       https://reddit.com/r/Meditation/comments/1l2u6gu/how_does_meditation_supposedly_help_people/   \n",
      "9                         https://reddit.com/r/Meditation/comments/1l2sku5/how_to_learn_tm_for_free/   \n",
      "\n",
      "           created_utc        link_flair_text  num_comments       id  \\\n",
      "0  2025-06-05T02:27:44    Sharing / Insight ðŸ’¡           0.0  1l3o2jc   \n",
      "1  2025-06-05T02:18:43    Sharing / Insight ðŸ’¡           2.0  1l3nwf4   \n",
      "2  2025-06-05T00:33:47           Discussion ðŸ’¬           2.0  1l3ls4c   \n",
      "3  2025-06-05T00:21:28    Sharing / Insight ðŸ’¡           4.0  1l3lj3v   \n",
      "4  2025-06-04T19:11:49    Sharing / Insight ðŸ’¡           1.0  1l3e8g9   \n",
      "5  2025-06-04T18:11:24             Question â“           6.0  1l3cowz   \n",
      "6  2025-06-04T07:23:49                  Other          35.0  1l2zdn0   \n",
      "7  2025-06-04T04:07:18    Sharing / Insight ðŸ’¡           3.0  1l2w8bh   \n",
      "8  2025-06-04T02:17:32  Spirituality :energy:          10.0  1l2u6gu   \n",
      "9  2025-06-04T00:57:31             Question â“          31.0  1l2sku5   \n",
      "\n",
      "   comment_depth  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "5            NaN  \n",
      "6            NaN  \n",
      "7            NaN  \n",
      "8            NaN  \n",
      "9            NaN  \n",
      "\n",
      "Total items scraped: 2977\n",
      "Number of posts scraped: 958\n",
      "Number of comments scraped: 2019\n",
      "Median Score: 4.0\n",
      "Average Score: 10.70\n",
      "Items by Subreddit:\n",
      "subreddit\n",
      "streamentry        1806\n",
      "Meditation          903\n",
      "zen                 126\n",
      "Buddhism            112\n",
      "selfimprovement      18\n",
      "Biohackers           11\n",
      "flowarts              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === âœ… Setup Reddit connection ===\n",
    "reddit = praw.Reddit(\n",
    "    client_id=reddit_client_id,\n",
    "    client_secret=reddit_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# === ðŸŽ¯ Subreddits to scan ===\n",
    "aussie_subs = [\n",
    "    \"meditation\", \"streamentry\", \"Buddhism\", \"Zen\",\n",
    "    \"biohackers\", \"flowarts\", \"selfimprovement\"\n",
    "]\n",
    "\n",
    "# === ðŸ‡¦ðŸ‡º Aussie context keywords (normalized) ===\n",
    "aussie_terms = [t.lower() for t in [\n",
    "    \"australia\", \"aussie\", \"nsw\", \"vic\", \"centrelink\", \"medicare\", \"mygov\",\n",
    "    \"woolies\", \"coles\", \"uni\", \"headspace\", \"black dog\", \"beyond blue\",\n",
    "    \"tafe\", \"smiling mind\", \"r u ok\", \"NDIS\", \"QLD\", \"ACT\", \"myki\", \"VIC Health\"\n",
    "]]\n",
    "\n",
    "# === ðŸ§˜ Meditation term pattern (fuzzy) ===\n",
    "meditation_pattern = re.compile(r\"\\bmeditat(?:ion|ing|e)?\\b\", re.IGNORECASE)\n",
    "\n",
    "# === ðŸ”Ž Scraping setup ===\n",
    "max_items = 5000\n",
    "scraped_count = 0\n",
    "results = []\n",
    "\n",
    "# === ðŸ•’ Time filter for last 2 years ===\n",
    "two_years_ago = datetime.utcnow() - timedelta(days=730)\n",
    "two_years_ago_timestamp = int(two_years_ago.timestamp())\n",
    "\n",
    "# === ðŸ” Phase 1: Scrape Posts ===\n",
    "logging.info(\"Phase 1: Scraping Posts...\")\n",
    "for sub in aussie_subs:\n",
    "    if scraped_count >= max_items:\n",
    "        break\n",
    "    logging.info(f\"ðŸ” Scanning r/{sub}...\")\n",
    "\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).new(limit=5000):\n",
    "            if scraped_count >= max_items:\n",
    "                break\n",
    "            if post.created_utc < two_years_ago_timestamp or post.score < 2:\n",
    "                continue\n",
    "\n",
    "            content = f\"{post.title} {post.selftext}\".lower()\n",
    "            flair = (post.link_flair_text or \"\").lower()\n",
    "            user_flair = (post.author_flair_text or \"\").lower()\n",
    "            has_meditation_term = meditation_pattern.search(content)\n",
    "            matched_aussie_terms = [\n",
    "                term for term in aussie_terms\n",
    "                if term in content or term in flair or term in user_flair\n",
    "            ]\n",
    "            if has_meditation_term and matched_aussie_terms:\n",
    "                results.append({\n",
    "                    \"type\": \"post\",\n",
    "                    \"subreddit\": post.subreddit.display_name,\n",
    "                    \"author\": str(post.author),\n",
    "                    \"score\": post.score,\n",
    "                    \"title\": post.title,\n",
    "                    \"full_text\": post.selftext[:4000],\n",
    "                    \"matched_terms\": matched_aussie_terms,\n",
    "                    \"url\": f\"https://reddit.com{post.permalink}\",\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(post.created_utc).isoformat(),\n",
    "                    \"link_flair_text\": post.link_flair_text,\n",
    "                    \"num_comments\": post.num_comments,\n",
    "                    \"id\": post.id\n",
    "                })\n",
    "                scraped_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping r/{sub} posts: {e}\")\n",
    "\n",
    "# === ðŸ’¬ Phase 2: Scrape Comments from Found Posts ===\n",
    "logging.info(\"\\nPhase 2: Scraping Comments from Found Posts...\")\n",
    "post_ids_to_check_comments = [r['id'] for r in results if r['type'] == 'post']\n",
    "\n",
    "for post_id in post_ids_to_check_comments:\n",
    "    if scraped_count >= max_items:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        submission = reddit.submission(id=post_id)\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        all_comments = submission.comments.list()\n",
    "        logging.info(f\"  Checking {len(all_comments)} comments in: {submission.title[:50]}...\")\n",
    "\n",
    "        for comment in all_comments:\n",
    "            if scraped_count >= max_items:\n",
    "                break\n",
    "            if comment.created_utc < two_years_ago_timestamp or comment.score < 2:\n",
    "                continue\n",
    "\n",
    "            body = comment.body.lower()\n",
    "            has_meditation_term = meditation_pattern.search(body)\n",
    "            matched_aussie_terms = [term for term in aussie_terms if term in body]\n",
    "\n",
    "            if has_meditation_term and matched_aussie_terms:\n",
    "                results.append({\n",
    "                    \"type\": \"comment\",\n",
    "                    \"subreddit\": comment.subreddit.display_name,\n",
    "                    \"author\": str(comment.author),\n",
    "                    \"score\": comment.score,\n",
    "                    \"title\": None,\n",
    "                    \"full_text\": comment.body[:4000],\n",
    "                    \"matched_terms\": matched_aussie_terms,\n",
    "                    \"url\": f\"https://reddit.com{comment.permalink}\",\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(comment.created_utc).isoformat(),\n",
    "                    \"link_flair_text\": None,\n",
    "                    \"comment_depth\": getattr(comment, \"depth\", None)\n",
    "                })\n",
    "                scraped_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping comments for post {post_id}: {e}\")\n",
    "\n",
    "# === ðŸ“Š Output Results ===\n",
    "df = pd.DataFrame(results).head(max_items)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(f\"\\nâœ… Scraped {len(df)} AU-relevant items mentioning meditation (target: {max_items}):\\n\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Stats\n",
    "print(f\"\\nTotal items scraped: {len(df)}\")\n",
    "print(f\"Number of posts scraped: {len(df[df['type'] == 'post'])}\")\n",
    "print(f\"Number of comments scraped: {len(df[df['type'] == 'comment'])}\")\n",
    "print(f\"Median Score: {df['score'].median()}\")\n",
    "print(f\"Average Score: {df['score'].mean():.2f}\")\n",
    "print(f\"Items by Subreddit:\\n{df['subreddit'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m_eq-HWjBR7"
   },
   "outputs": [],
   "source": [
    "# âœ… Setup Reddit connection\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "#original script#replaced by above optimised one\n",
    "reddit = praw.Reddit(\n",
    "    client_id=reddit_client_id,\n",
    "    client_secret=reddit_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "# ðŸŽ¯ Subreddits to scan\n",
    "aussie_subs = [\n",
    "    \"meditation\",       # Core subreddit\n",
    "    \"streamentry\",      # Hardcore Buddhist meditation community\n",
    "    \"Buddhism\",         # Vipassana and insight posts\n",
    "    \"Zen\",               # R/zen â€” Koans, concentration, awareness\n",
    "    \"biohackers\",       # NSDR, nootropics, breathwork\n",
    "    \"flowarts\",         # Movement meditation, flow\n",
    "    \"selfimprovement\"   # Habit-building overlap\n",
    "]\n",
    "\n",
    "\n",
    "# === ðŸ‡¦ðŸ‡º Aussie context keywords (normalized) ===\n",
    "aussie_terms = [t.lower() for t in [\n",
    "    \"australia\", \"aussie\", \"nsw\", \"vic\", \"centrelink\", \"medicare\", \"mygov\",\n",
    "    \"woolies\", \"coles\", \"uni\", \"headspace\", \"black dog\", \"beyond blue\",\n",
    "    \"tafe\", \"smiling mind\", \"r u ok\", \"NDIS\", \"QLD\", \"ACT\", \"myki\", \"VIC Health\"\n",
    "]]\n",
    "\n",
    "# === ðŸ§˜ Meditation term pattern (fuzzy) ===\n",
    "meditation_pattern = re.compile(r\"\\bmeditat(?:ion|ing|e)?\\b\", re.IGNORECASE)\n",
    "\n",
    "# === ðŸ”Ž Scraping setup ===\n",
    "max_items = 2\n",
    "scraped_count = 0\n",
    "results = []\n",
    "# We will handle the date filtering differently depending on the method used\n",
    "\n",
    "# Set a target timestamp for the last 2 years, but note that methods like .new()\n",
    "# don't use 'after' with a timestamp like search does. We'll filter later.\n",
    "# Time threshold\n",
    "two_years_ago = datetime.utcnow() - timedelta(days=730)\n",
    "two_years_ago_timestamp = int(two_years_ago.timestamp())\n",
    "\n",
    "# === ðŸ” Scrape Posts First (using .new() with time_filter or .top()) ===\n",
    "# Trying .new() with 'year' time_filter first\n",
    "logging.info(\"Phase 1: Scraping Posts...\")\n",
    "for sub in aussie_subs:\n",
    "    if scraped_count >= max_items:\n",
    "        break\n",
    "    logging.info(f\"ðŸ” Scanning recent posts in r/{sub}...\")\n",
    "\n",
    "    try:\n",
    "        # Use .new() with time_filter 'year' to get recent posts within the last year\n",
    "        # Note: This is approximate and doesn't guarantee exactly 2 years. We filter later.\n",
    "        for post in reddit.subreddit(sub).new(limit=3000): # Increased limit per sub to find more candidates\n",
    "            if scraped_count >= max_items:\n",
    "                break\n",
    "\n",
    "            # Apply time filter (explicitly check timestamp)\n",
    "            if post.created_utc < two_years_ago_timestamp:\n",
    "                continue # Skip if older than 2 years\n",
    "\n",
    "\n",
    "            # Filter criteria: meditation keyword, Aussie context, score >= 2\n",
    "            content = f\"{post.title} {post.selftext}\".lower()\n",
    "            flair = (post.link_flair_text or \"\").lower()\n",
    "            user_flair = (post.author_flair_text or \"\").lower()\n",
    "            matched_aussie_terms = [term for term in aussie_terms if term in content or term in flair or term in user_flair]\n",
    "            has_meditation_term = meditation_pattern.search(content) is not None\n",
    "            meets_score = post.score >= 2\n",
    "\n",
    "            if has_meditation_term and matched_aussie_terms and meets_score:\n",
    "                results.append({\n",
    "                    \"type\": \"post\",\n",
    "                    \"subreddit\": post.subreddit.display_name,\n",
    "                    \"author\": str(post.author),\n",
    "                    \"score\": post.score,\n",
    "                    \"title\": post.title,\n",
    "                    \"full_text\": post.selftext[:4000],\n",
    "                    \"matched_terms\": matched_aussie_terms,\n",
    "                    \"url\": f\"https://reddit.com{post.permalink}\",\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(post.created_utc).isoformat(),\n",
    "                    \"link_flair_text\": post.link_flair_text,\n",
    "                    \"num_comments\": post.num_comments,\n",
    "                    \"id\": post.id # Store ID to fetch comments later\n",
    "                })\n",
    "                scraped_count += 1\n",
    "                # logging.info(f\"  Found post: {post.title} (Score: {post.score}, Scraped: {scraped_count})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping r/{sub} posts: {e}\")\n",
    "\n",
    "\n",
    "# === ðŸ’¬ Scrape Comments from the Scraped Posts ===\n",
    "# This is much more targeted and efficient than scraping all comments in a subreddit.\n",
    "logging.info(\"\\nPhase 2: Scraping Comments from Found Posts...\")\n",
    "post_ids_to_check_comments = [r['id'] for r in results if r['type'] == 'post'] # Get IDs of found posts\n",
    "\n",
    "for post_id in post_ids_to_check_comments:\n",
    "    if scraped_count >= max_items:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        submission = reddit.submission(id=post_id)\n",
    "        # Fetch all comments from the submission (Reddit may return a forest, not just top level)\n",
    "        # Use replace_more(limit=0) to avoid fetching potentially huge amounts of 'MoreComments' objects\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        all_comments = submission.comments.list()\n",
    "\n",
    "        logging.info(f\"  Checking {len(all_comments)} comments for post: {submission.title[:50]}...\")\n",
    "\n",
    "        for comment in all_comments:\n",
    "            if scraped_count >= max_items:\n",
    "                break\n",
    "\n",
    "            # Skip if older than 2 years (check comment creation time)\n",
    "            if comment.created_utc < two_years_ago_timestamp:\n",
    "                continue # Skip if older than 2 years\n",
    "\n",
    "            body = comment.body.lower()\n",
    "\n",
    "            # Filter criteria: meditation keyword, Aussie context, score >= 2\n",
    "            has_meditation_term = meditation_pattern.search(body) is not None\n",
    "            matched_aussie_terms = [term for term in aussie_terms if term in body]\n",
    "            meets_score = comment.score >= 2\n",
    "\n",
    "            if has_meditation_term and matched_aussie_terms and meets_score:\n",
    "                results.append({\n",
    "                    \"type\": \"comment\",\n",
    "                    \"subreddit\": comment.subreddit.display_name,\n",
    "                    \"author\": str(comment.author),\n",
    "                    \"score\": comment.score,\n",
    "                    \"title\": None, # Comments don't have titles\n",
    "                    \"full_text\": comment.body[:4000],\n",
    "                    \"matched_terms\": matched_aussie_terms,\n",
    "                    \"url\": f\"https://reddit.com{comment.permalink}\",\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(comment.created_utc).isoformat(),\n",
    "                    \"link_flair_text\": None, # Comments don't have link flair\n",
    "                    \"comment_depth\": getattr(comment, \"depth\", None)\n",
    "                })\n",
    "                scraped_count += 1\n",
    "                # logging.info(f\"    Found comment (Score: {comment.score}, Scraped: {scraped_count})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping comments for post {post_id}: {e}\")\n",
    "\n",
    "# === ðŸ“Š Output results ===\n",
    "df = pd.DataFrame(results)\n",
    "# Ensure we only keep the required number of items if we exceeded max_items during the process\n",
    "df = df.head(max_items)\n",
    "\n",
    "# Sort by score or another relevant metric to potentially show higher quality results first\n",
    "#df = df.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"\\nâœ… Scraped {len(df)} AU-relevant items mentioning meditation (target: {max_items}):\\n\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Display some stats\n",
    "print(f\"\\nTotal items scraped: {len(df)}\")\n",
    "print(f\"Number of posts scraped: {len(df[df['type'] == 'post'])}\")\n",
    "print(f\"Number of comments scraped: {len(df[df['type'] == 'comment'])}\")\n",
    "print(f\"Median Score: {df['score'].median()}\")\n",
    "print(f\"Average Score: {df['score'].mean():.2f}\")\n",
    "print(f\"Items by Subreddit:\\n{df['subreddit'].value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg7yWbzUblAk"
   },
   "outputs": [],
   "source": [
    "# To optimise and hit the 1000 target:\n",
    "# - Focus scraping on more targeted subreddits first.\n",
    "# - Use the `subreddit.new()` or `subreddit.controversial()` or `subreddit.top()` methods with a time filter (`time_filter='year'` or `time_filter='all'`) instead of `search` for posts, as these can be more effective for recent activity within a time window.\n",
    "# - For comments, instead of iterating *all* comments, iterate through the comments of the *scraped posts* that met the initial criteria. This keeps the comment search relevant to the found posts.\n",
    "# - Increase the limits for initial post scraping to allow more potential candidates before filtering.\n",
    "# - Implement a more dynamic approach that potentially increases the scrape depth or expands search criteria if the initial pass doesn't yield enough results.\n",
    "# - Prioritize scoring potentially higher based on keywords or subreddits if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "h7C81MLYVzp5",
    "outputId": "cd4373af-8134-4778-831c-f7843ef8b5bc"
   },
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name df does not exist!\nDid you mean \"pg_depend\"?\n\nLINE 1: CREATE TABLE reddit_meditation_au AS SELECT * FROM df\n                                                           ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aed084b91ff8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduckdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DROP TABLE IF EXISTS {table_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CREATE TABLE {table_name} AS SELECT * FROM df\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Table with name df does not exist!\nDid you mean \"pg_depend\"?\n\nLINE 1: CREATE TABLE reddit_meditation_au AS SELECT * FROM df\n                                                           ^"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Generate timestamped filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "db_file = f\"reddit_{timestamp}.duckdb\"\n",
    "table_name = \"reddit_meditation_au\"\n",
    "\n",
    "# Save table\n",
    "con = duckdb.connect(db_file)\n",
    "con.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "con.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM df\")\n",
    "con.close()\n",
    "\n",
    "print(f\"âœ… Saved table '{table_name}' to {db_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uecu0qzZNo6J",
    "outputId": "0cf35a7e-0333-48bb-9a3a-e9a85c04bf8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Tables before copy: [('reddit_meditation_au',)]\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(db_file)\n",
    "tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "print(\"ðŸ“‹ Tables before copy:\", tables)\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYlw2AEROp-P",
    "outputId": "35440ec8-bbfb-4daf-a870-c9ed64db6c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "âœ… Copied 'reddit_20250606_190637.duckdb' to Drive â†’ /content/drive/MyDrive/reddit_data/reddit_20250606_190637.duckdb\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define paths\n",
    "drive_path = '/content/drive/MyDrive/reddit_data'\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "# Copy using same name\n",
    "dest_file = os.path.join(drive_path, db_file)\n",
    "shutil.copy(db_file, dest_file)\n",
    "print(f\"âœ… Copied '{db_file}' to Drive â†’ {dest_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVRfmbhmkDPG"
   },
   "source": [
    "## Section 2. double checl Reload data successfully from Google Drive## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXh6G5CjiNWM",
    "outputId": "f7888eb2-a81f-4a26-85c9-2e50e803261e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "ðŸ“‹ Tables in Drive copy: [('reddit_meditation_au',)]\n"
     ]
    }
   ],
   "source": [
    "# âœ… Step 1: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# âœ… Step 2: Set full path to your DuckDB file\n",
    "import duckdb\n",
    "\n",
    "dest_file = \"/content/drive/MyDrive/reddit_data/reddit_20250605_083205.duckdb\"\n",
    "\n",
    "# Connect to the file\n",
    "con = duckdb.connect(dest_file)\n",
    "# âœ… Step 3: Check available tables\n",
    "tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "print(\"ðŸ“‹ Tables in Drive copy:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZ110j8GN8m1",
    "outputId": "b5b82e19-f63b-4700-a61b-242139816542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 1 rows from Drive copy.\n"
     ]
    }
   ],
   "source": [
    "# Try loading\n",
    "df_loaded = con.execute(\"SELECT * FROM reddit_meditation_au\").df()\n",
    "print(f\"âœ… Loaded {len(df_loaded)} rows from Drive copy.\")\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XITeKFqCNFF",
    "outputId": "dcca2a35-f471-4081-a0e5-f6708edb04c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type   subreddit        author  score  \\\n",
      "0  post  Meditation  Anima_Monday      2   \n",
      "\n",
      "                                                        title  \\\n",
      "0  Equanimity and Non-Attachment Meditation, A Novel Approach   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \\\n",
      "0  This practice uses phrases for equanimity and non-attachment in a similar way to the ones for popular forms of metta bhavana (loving kindness) meditation.\\n\\nI developed this specific form that I am sharing here myself and am being transparent about this, so you can see it as a novel approach. Popular metta practice has phrases that one repeats as part of the process, such as 'may all beings be well'. Below are phrases for equanimity and non-attachment. This is just a possible way to approach it, one way to put the mind in the mode of equanimity and non-attachment, so that this state can then be abided in directly. You can try it out if you are interested. I am just passing on something which has been helpful for me as perhaps it may help others too.\\n\\nYou can mentally say the phrases, with the first part of each phrase being on the in-breath, and the second part (the 'fine') being on the out-breath. Doing this while breathing naturally, meaning not deliberately controlling the breath. Try it with eyes closed, and then if you wish, you can experiment with eyes open on some occasions to integrate it into the sense experience and make it gradually more available 'off the mat'.\\n\\nSo mentally saying these phrases while in the relative stillness and safety of a meditation posture, either sitting or lying down, and syncing it to the breathing:\\n\\n\"If it comes ... fine\\n\\nIf it doesn't come ... fine\\n\\nIf it changes ... fine\\n\\nIf it doesn't change ... fine\\n\\nIf it goes ... fine\\n\\nIf it doesn't go ... fine\"\\n\\nYou meditate like this until there is a natural sense of equanimity and non-attachment, a natural letting go into that, which might occur after only doing it once through, or it might take a bit longer with more repetitions. It puts the mind closer in attitude to the nature unconditional awareness which is the deeper reality of oneself. A letting go occurs and you more naturally abide in/as this unconditional awareness.\\n\\nDo the phrases at least once through, and then repeat as needed. When the phrases seem like they are no longer needed, then allow them to cease and then abide naturally as you are. If they become needed again at any point, then you can repeat them again, or just the ones that are needed as appropriate.   \n",
      "\n",
      "  matched_terms  \\\n",
      "0         [act]   \n",
      "\n",
      "                                                                                                 url  \\\n",
      "0  https://reddit.com/r/Meditation/comments/1l3o2jc/equanimity_and_nonattachment_meditation_a_novel/   \n",
      "\n",
      "           created_utc      link_flair_text  num_comments       id  \\\n",
      "0  2025-06-05T02:27:44  Sharing / Insight ðŸ’¡           0.0  1l3o2jc   \n",
      "\n",
      "   comment_depth  \n",
      "0            NaN  \n",
      "\n",
      "ðŸ“Š Summary:\n",
      "- Total items: 1\n",
      "- Posts: 1\n",
      "- Comments: 0\n",
      "- Median Score: 2.0\n",
      "- Average Score: 2.00\n",
      "\n",
      "ðŸ”Ž Items by Subreddit:\n",
      "subreddit\n",
      "Meditation    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# === ðŸ“Š STEP 4: Preview & Summary ===\n",
    "if not df_loaded.empty:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(df_loaded.head(10))\n",
    "\n",
    "    # Summary stats\n",
    "    print(\"\\nðŸ“Š Summary:\")\n",
    "    print(f\"- Total items: {len(df_loaded)}\")\n",
    "    print(f\"- Posts: {len(df_loaded[df_loaded['type'] == 'post'])}\")\n",
    "    print(f\"- Comments: {len(df_loaded[df_loaded['type'] == 'comment'])}\")\n",
    "    print(f\"- Median Score: {df_loaded['score'].median()}\")\n",
    "    print(f\"- Average Score: {df_loaded['score'].mean():.2f}\")\n",
    "    print(\"\\nðŸ”Ž Items by Subreddit:\")\n",
    "    print(df_loaded['subreddit'].value_counts())\n",
    "else:\n",
    "    print(\"No data loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OR5fMJ1Owtx"
   },
   "source": [
    "## Section 3. LLMs: Summary, key themes, pain points, and emotions## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "id": "Vya9mA56IIED"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Re1voqx4Tr5x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khqutx8e9e0t"
   },
   "source": [
    "## Breakdown for production## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cn9oJZK42-9v",
    "outputId": "55e17244-d84d-481b-bb2d-07d0e208af79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "scXNuKfc9sKr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctK66A9B9suy",
    "outputId": "ea285f02-c882-4aee-825f-f93259ff86f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "ðŸ“‹ Tables in Drive copy: [('reddit_meditation_au',)]\n"
     ]
    }
   ],
   "source": [
    "# âœ… Step 1: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# âœ… Step 2: Set full path to your DuckDB file\n",
    "import duckdb\n",
    "\n",
    "dest_file = \"/content/drive/MyDrive/reddit_data/reddit_20250605_083205.duckdb\"\n",
    "\n",
    "# Connect to the file\n",
    "con = duckdb.connect(dest_file)\n",
    "# âœ… Step 3: Check available tables\n",
    "tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "print(\"ðŸ“‹ Tables in Drive copy:\", tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Bn3RG_w9s3t",
    "outputId": "c4775527-6b62-46f4-b177-66e53a0e7b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 2977 rows from Drive copy.\n"
     ]
    }
   ],
   "source": [
    "# Try loading\n",
    "df_loaded = con.execute(\"SELECT * FROM reddit_meditation_au\").df()\n",
    "print(f\"âœ… Loaded {len(df_loaded)} rows from Drive copy.\")\n",
    "con.close()\n",
    "# --- Validate Input ---\n",
    "if \"full_text\" not in df_loaded.columns:\n",
    "    raise ValueError(\"âŒ 'full_text' column is missing from df_loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCrNBDzYPC5Z"
   },
   "source": [
    "## GoEmotions is a corpus of 58k carefully curated comments extracted from Reddit, with human annotations to 27 emotion categories, along with label Neutral.## \n",
    "\n",
    "References:\n",
    "*   GoEmotions Dataset on Hugging Face: https://huggingface.co/datasets/google-research-datasets/go_emotions\n",
    "*   Google Research Blog: GoEmotions: A Dataset for Fine-Grained Emotion Classification(https://research.google/blog/goemotions-a-dataset-for-fine-grained-emotion-classification/)\n",
    "*  Original Paper: GoEmotions: A Dataset of Fine-Grained Emotions\n",
    "(https://arxiv.org/abs/2005.00547)\n",
    "\n",
    "\n",
    "For a comprehensive list of the emotion labels and additional details, you can refer to the dataset's README on Hugging Face: https://huggingface.co/datasets/google-research-datasets/go_emotions/blob/main/README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "aBjzhYom-0LY"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "emotion_model_id = \"joeddav/distilbert-base-uncased-go-emotions-student\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# âœ… Load model and convert to float16\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    emotion_model_id\n",
    ").to(device).half().eval()  # .half() here\n",
    "\n",
    "emotion_tokenizer = AutoTokenizer.from_pretrained(emotion_model_id)\n",
    "\n",
    "\n",
    "emotion_labels = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\",\n",
    "    \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\",\n",
    "    \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "092a531d1ccc4d10b847005c33e98151",
      "eb5d495fa1fa47049161a378e5d6f7bf",
      "69f9cfc5a9024466b39fea2df5e38eed",
      "dd87e61e876f4e80a41ccadfad3153f9",
      "cfb33ffc6d04499cb2f97b1c3deb333a",
      "70c4c7522779453281948e029a03eec9",
      "e5dc43b6ebd846bdb05327105ffb769f",
      "7720959707c64e35b310e25d50e432a0",
      "56ac531a7af44ca6ac6610d6b101678f",
      "3e57833e4c9044c18980d89e730cf348",
      "9c7b710d643b404182aec22e732a93f5"
     ]
    },
    "collapsed": true,
    "id": "tYW5vJ1c_8Lp",
    "outputId": "b251e426-d652-47ee-f1cd-784d2def0f45"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092a531d1ccc4d10b847005c33e98151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16  # A100 supports float16\n",
    ")\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dUE1Rs5XChPW"
   },
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Carefully analyze the following user-generated content. Focus only on language related to meditation, mindfulness, emotional states, or experiences involving flow, awareness, or self-regulation â€” including any occasions, motivations, or purposes behind engaging in these practices.\n",
    "Read the text below and complete the 9 tasks that follow.\n",
    "---\n",
    "{text}\n",
    "---\n",
    "\n",
    "Perform the following tasks with attention to the userâ€™s original language and context:\n",
    "\n",
    "Tasks:\n",
    "1. Summarize only the parts related to meditation, mindfulness, flow, or self-regulation.\n",
    "2. List userâ€™s pain points using their exact words (no rephrasing).\n",
    "3. List emotional expressions using the user's original words.\n",
    "4. Give the overall emotion in 1 word (e.g., â€œanxiousâ€, â€œcalmâ€).\n",
    "5. Give a sentiment score from -1 (negative) to +1 (positive).\n",
    "6. Label sentiment as \"positive\" or \"negative\".\n",
    "7. Identify the single most prominent theme in 1â€“3 words(e.g., \"letting go\", \"inner peace\").\n",
    "8. Infer a likely demographic identity (\"unknown\" if unclear).\n",
    "9. List phrases from the text that led to your demographic guess.\n",
    "\n",
    "\n",
    "Return the answer in **exactly this JSON format**:\n",
    "\n",
    "{{\n",
    "  \"summary\": \"...\",\n",
    "  \"pain_points\": [\"...\"],\n",
    "  \"emotion_phrases\": [\"...\"],\n",
    "  \"emotion_label\": \"...\",\n",
    "  \"sentiment_score\": 0.42,\n",
    "  \"sentiment\": \"positive\",\n",
    "  \"themes\": [\"...\"],\n",
    "  \"demographic_proximity\": \"...\",\n",
    "  \"demographic_evidence_phrases\": [\"...\"]\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ulU9W-dOCUcO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "# --- Global GPU-safe fallback constants ---\n",
    "_JSON_FAIL_RESPONSE = {\"success\": False, \"data\": None, \"error\": \"JSON parse failed\"}\n",
    "_EMOTION_FAIL_RESPONSE = lambda text: {\n",
    "    \"success\": False,\n",
    "    \"data\": dict(zip(emotion_labels, [None]*len(emotion_labels))),\n",
    "    \"error\": \"Emotion model failure\",\n",
    "    \"text\": text\n",
    "}\n",
    "\n",
    "# --- Fix common JSON key issues (e.g., unquoted keys) ---\n",
    "def fix_json_keys(raw_str):\n",
    "    return re.sub(r'(?<={|,)\\s*(\\w+)\\s*:', r'\"\\1\":', raw_str)\n",
    "\n",
    "# --- Extract last JSON block from raw output ---\n",
    "def extract_last_json_block(output_text):\n",
    "    matches = list(re.finditer(r'\\{[\\s\\S]*?\\}', output_text))\n",
    "    return matches[-1].group(0) if matches else None\n",
    "\n",
    "# --- Retry decorator for fault-tolerant inference ---\n",
    "def retry_on_fail(max_retries=1, wait_seconds=1.0):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(max_retries + 1):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except torch.cuda.OutOfMemoryError as e:\n",
    "                    print(f\"ðŸ”¥ GPU OOM on attempt {attempt + 1}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    time.sleep(wait_seconds)\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {func.__name__} failed on attempt {attempt + 1}: {e}\")\n",
    "                    time.sleep(wait_seconds)\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# --- JSON parsing after LLM generation ---\n",
    "@retry_on_fail(max_retries=1)\n",
    "@torch.inference_mode()\n",
    "def safe_generate_and_parse(input_text: str, tokenizer, model, template: str, max_tokens=512, row_id: Optional[int] = None):\n",
    "    prompt = template.replace(\"{text}\", input_text.strip())\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    json_str = extract_last_json_block(decoded)\n",
    "\n",
    "    if not json_str:\n",
    "        print(f\"âŒ [{row_id}] No JSON found.\\nRaw output:\\n{decoded[:300]}\")\n",
    "        return _JSON_FAIL_RESPONSE | {\"raw\": decoded, \"row_id\": row_id}\n",
    "\n",
    "    try:\n",
    "        return {\"success\": True, \"data\": json.loads(json_str), \"row_id\": row_id}\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            fixed_str = fix_json_keys(json_str)\n",
    "            return {\"success\": True, \"data\": json.loads(fixed_str), \"row_id\": row_id}\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âŒ [{row_id}] JSON error after fix: {e}\")\n",
    "            return _JSON_FAIL_RESPONSE | {\"raw\": fixed_str, \"row_id\": row_id}\n",
    "\n",
    "# --- Emotion classifier (GoEmotions-style multi-label) ---\n",
    "@retry_on_fail(max_retries=1)\n",
    "@torch.inference_mode()\n",
    "def get_emotion_vector(text: str, tokenizer, model, labels, device=\"cuda\"):\n",
    "    try:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
    "        return {\"success\": True, \"data\": dict(zip(labels, probs)), \"text\": text}\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Emotion model error: {e}\")\n",
    "        return _EMOTION_FAIL_RESPONSE(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zN3z_His_cD_",
    "outputId": "e10ed8bb-8c1a-4f62-bd49-f4d111e7f1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â© Resuming from checkpoint at row 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Batch 0â€“99\n",
      "âŒ [62] JSON error after fix: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:   3%|â–Ž         | 1/30 [15:02<7:16:01, 902.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 0â€“99 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 902.1 seconds\n",
      "\n",
      "ðŸš€ Batch 100â€“199\n",
      "âŒ [126] JSON error after fix: Invalid \\escape: line 3 column 125 (char 321)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:   7%|â–‹         | 2/30 [28:49<6:40:21, 857.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 100â€“199 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 826.96 seconds\n",
      "\n",
      "ðŸš€ Batch 200â€“299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  10%|â–ˆ         | 3/30 [42:20<6:16:25, 836.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 200â€“299 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 811.07 seconds\n",
      "\n",
      "ðŸš€ Batch 300â€“399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  10%|â–ˆ         | 3/30 [44:09<6:37:26, 883.22s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-4b44390e20f5>\", line 51, in <cell line: 0>\n",
      "    parsed = safe_generate_and_parse(input_text=text, tokenizer=llm_tokenizer, model=llm_model, template=TEMPLATE, row_id=idx)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-12-cec7f6b50207>\", line 31, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-12-cec7f6b50207>\", line 50, in safe_generate_and_parse\n",
      "    output = model.generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 2597, in generate\n",
      "    result = self._sample(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 3560, in _sample\n",
      "    outputs = model_forward(**model_inputs, return_dict=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
      "    output = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\", line 690, in forward\n",
      "    outputs: BaseModelOutputWithPast = self.model(\n",
      "                                       ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
      "    output = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\", line 423, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\", line 48, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\", line 244, in forward\n",
      "    hidden_states, self_attn_weights = self.self_attn(\n",
      "                                       ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\", line 169, in forward\n",
      "    key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py\", line 546, in update\n",
      "    self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], value_states], dim=-2)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
      "    traceback_info = getframeinfo(tb, context)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1667, in getframeinfo\n",
      "    positions = _get_code_position_from_tb(frame)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1649, in _get_code_position_from_tb\n",
      "    return _get_code_position(code, instruction_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1656, in _get_code_position\n",
      "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4b44390e20f5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# --- Run models ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_generate_and_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEMPLATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_emotion_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotion_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotion_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotion_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cec7f6b50207>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfMemoryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cec7f6b50207>\u001b[0m in \u001b[0;36msafe_generate_and_parse\u001b[0;34m(input_text, tokenizer, model, template, max_tokens, row_id)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     output = model.generate(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2598\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3559\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3560\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    691\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    424\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mcache_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"sin\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cos\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cache_position\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcache_position\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Config ---\n",
    "BATCH_SIZE = 100\n",
    "TABLE_NAME = \"reddit_nlp_features\"\n",
    "DRIVE_SUBFOLDER = \"/content/drive/MyDrive/reddit_data\"\n",
    "DRIVE_DB_FILE = os.path.join(DRIVE_SUBFOLDER, \"reddit_progress.duckdb\")\n",
    "CHECKPOINT_FILE = \"checkpoint.txt\"\n",
    "\n",
    "# --- Ensure Drive is mounted ---\n",
    "assert os.path.exists(DRIVE_SUBFOLDER), \"Google Drive folder not found. Please mount Drive first.\"\n",
    "\n",
    "# --- Connect to DuckDB directly in Drive ---\n",
    "conn = duckdb.connect(DRIVE_DB_FILE)\n",
    "\n",
    "# --- Fetch schema if table exists ---\n",
    "try:\n",
    "    table_cols = [col[1] for col in conn.execute(f\"PRAGMA table_info({TABLE_NAME})\").fetchall()]\n",
    "except:\n",
    "    table_cols = []\n",
    "\n",
    "# --- Resume from checkpoint ---\n",
    "start_index = 0\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "        start_index = int(f.read().strip())\n",
    "    print(f\"â© Resuming from checkpoint at row {start_index}\")\n",
    "\n",
    "# --- Track failures ---\n",
    "failed_rows = []\n",
    "\n",
    "# --- Main Batch Loop ---\n",
    "for start_idx in tqdm(range(start_index, len(df_loaded), BATCH_SIZE), desc=\"ðŸ”„ Processing Batches\"):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, len(df_loaded))\n",
    "    print(f\"\\nðŸš€ Batch {start_idx}â€“{end_idx - 1}\")\n",
    "    batch_start_time = datetime.now()\n",
    "\n",
    "    batch = df_loaded.iloc[start_idx:end_idx]\n",
    "    combined_rows = []\n",
    "\n",
    "    for idx, row in batch.iterrows():\n",
    "        try:\n",
    "            text = str(row.get(\"full_text\", \"\"))[:1800]\n",
    "            row_meta = row.drop(labels=[\"full_text\"]).to_dict()\n",
    "\n",
    "            # --- Run models ---\n",
    "            parsed = safe_generate_and_parse(input_text=text, tokenizer=llm_tokenizer, model=llm_model, template=TEMPLATE, row_id=idx)\n",
    "            emotion = get_emotion_vector(text=text, tokenizer=emotion_tokenizer, model=emotion_model, labels=emotion_labels, device=device)\n",
    "\n",
    "            if parsed[\"success\"] and emotion[\"success\"]:\n",
    "                combined = {\n",
    "                    **row_meta,\n",
    "                    **parsed[\"data\"],\n",
    "                    **emotion[\"data\"],\n",
    "                    \"row_index\": idx,\n",
    "                    \"text\": text\n",
    "                }\n",
    "\n",
    "                # Flatten lists\n",
    "                for k, v in combined.items():\n",
    "                    if hasattr(v, \"tolist\"):\n",
    "                        v = v.tolist()\n",
    "                    if isinstance(v, list) and all(isinstance(i, str) for i in v):\n",
    "                        combined[k] = \"; \".join(v)\n",
    "                    else:\n",
    "                        combined[k] = v\n",
    "\n",
    "                combined_rows.append(combined)\n",
    "            else:\n",
    "                failed_rows.append({\n",
    "                    \"row_index\": idx,\n",
    "                    \"error\": parsed.get(\"error\") or emotion.get(\"error\"),\n",
    "                    \"text\": text[:300]\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_rows.append({\n",
    "                \"row_index\": idx,\n",
    "                \"error\": str(e),\n",
    "                \"text\": text[:300]\n",
    "            })\n",
    "\n",
    "    # --- Save batch to DuckDB ---\n",
    "    if combined_rows:\n",
    "        df_combined = pd.DataFrame(combined_rows)\n",
    "\n",
    "        if table_cols:\n",
    "            df_combined = df_combined[[col for col in df_combined.columns if col in table_cols]]\n",
    "        else:\n",
    "            table_cols = df_combined.columns.tolist()\n",
    "            conn.execute(f\"CREATE TABLE IF NOT EXISTS {TABLE_NAME} AS SELECT * FROM df_combined LIMIT 0\")\n",
    "\n",
    "        conn.execute(f\"INSERT INTO {TABLE_NAME} SELECT * FROM df_combined\")\n",
    "        print(f\"âœ… Batch {start_idx}â€“{end_idx - 1} saved to {TABLE_NAME}\")\n",
    "\n",
    "        # --- Save checkpoint (start of this batch for retry safety) ---\n",
    "        with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "            f.write(str(start_idx))\n",
    "        print(\"ðŸ“ Checkpoint updated.\")\n",
    "\n",
    "        # --- Duration log ---\n",
    "        duration = (datetime.now() - batch_start_time).total_seconds()\n",
    "        print(f\"â±ï¸ Duration: {round(duration, 2)} seconds\")\n",
    "\n",
    "# --- Close DB connection ---\n",
    "conn.close()\n",
    "\n",
    "# --- Save failures if any ---\n",
    "if failed_rows:\n",
    "    pd.DataFrame(failed_rows).to_csv(\"failed_rows.csv\", index=False)\n",
    "    print(f\"âš ï¸ {len(failed_rows)} failed rows logged to failed_rows.csv\")\n",
    "\n",
    "print(f\"\\nðŸ Done! All processed data written to {TABLE_NAME} in Google Drive DuckDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoW6pXe2ZFnI",
    "outputId": "fe9ddd9b-9a44-410a-f7b3-84b4164662e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â© Resuming from checkpoint at row 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Batch 300â€“399\n",
      "âŒ [347] JSON error after fix: Expecting ',' delimiter: line 2 column 161 (char 162)\n",
      "âŒ [390] JSON error after fix: Invalid \\escape: line 3 column 144 (char 485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:   4%|â–Ž         | 1/27 [14:30<6:17:16, 870.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 300â€“399 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 870.63 seconds\n",
      "\n",
      "ðŸš€ Batch 400â€“499\n",
      "âŒ [428] JSON error after fix: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "âŒ [470] JSON error after fix: Expecting property name enclosed in double quotes: line 11 column 1 (char 961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:   7%|â–‹         | 2/27 [28:40<5:57:43, 858.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 400â€“499 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 850.06 seconds\n",
      "\n",
      "ðŸš€ Batch 500â€“599\n",
      "âŒ [514] JSON error after fix: Expecting ',' delimiter: line 4 column 128 (char 627)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  11%|â–ˆ         | 3/27 [42:03<5:33:10, 832.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 500â€“599 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 802.46 seconds\n",
      "\n",
      "ðŸš€ Batch 600â€“699\n",
      "âŒ [652] JSON error after fix: Expecting property name enclosed in double quotes: line 11 column 1 (char 759)\n",
      "âŒ [657] JSON error after fix: Expecting property name enclosed in double quotes: line 11 column 1 (char 1189)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  15%|â–ˆâ–        | 4/27 [56:17<5:22:36, 841.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 600â€“699 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 854.84 seconds\n",
      "\n",
      "ðŸš€ Batch 700â€“799\n",
      "âŒ [762] JSON error after fix: Expecting ',' delimiter: line 2 column 158 (char 159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  19%|â–ˆâ–Š        | 5/27 [1:11:06<5:14:49, 858.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 700â€“799 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 888.85 seconds\n",
      "\n",
      "ðŸš€ Batch 800â€“899\n",
      "âŒ [854] JSON error after fix: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "âŒ [888] JSON error after fix: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  22%|â–ˆâ–ˆâ–       | 6/27 [1:25:40<5:02:19, 863.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 800â€“899 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 873.85 seconds\n",
      "\n",
      "ðŸš€ Batch 900â€“999\n",
      "âŒ [943] JSON error after fix: Expecting ',' delimiter: line 10 column 41 (char 682)\n",
      "âŒ [993] JSON error after fix: Expecting value: line 4 column 286 (char 551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  26%|â–ˆâ–ˆâ–Œ       | 7/27 [1:39:02<4:41:09, 843.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 900â€“999 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 801.56 seconds\n",
      "\n",
      "ðŸš€ Batch 1000â€“1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  30%|â–ˆâ–ˆâ–‰       | 8/27 [1:51:40<4:18:30, 816.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1000â€“1099 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 758.3 seconds\n",
      "\n",
      "ðŸš€ Batch 1100â€“1199\n",
      "âŒ [1159] JSON error after fix: Expecting ',' delimiter: line 4 column 74 (char 294)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 9/27 [2:04:32<4:00:45, 802.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1100â€“1199 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 772.13 seconds\n",
      "\n",
      "ðŸš€ Batch 1200â€“1299\n",
      "âŒ [1278] JSON error after fix: Expecting ',' delimiter: line 3 column 180 (char 274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [2:17:24<3:44:40, 792.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1200â€“1299 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 771.57 seconds\n",
      "\n",
      "ðŸš€ Batch 1300â€“1399\n",
      "âŒ [1348] JSON error after fix: Expecting ',' delimiter: line 2 column 48 (char 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [2:30:31<3:30:58, 791.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1300â€“1399 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 787.12 seconds\n",
      "\n",
      "ðŸš€ Batch 1400â€“1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [2:44:14<3:20:15, 801.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1400â€“1499 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 823.56 seconds\n",
      "\n",
      "ðŸš€ Batch 1500â€“1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [2:57:39<3:07:10, 802.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1500â€“1599 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 804.82 seconds\n",
      "\n",
      "ðŸš€ Batch 1600â€“1699\n",
      "âŒ [1653] JSON error after fix: Expecting ',' delimiter: line 3 column 110 (char 428)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [3:11:39<2:56:14, 813.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1600â€“1699 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 839.44 seconds\n",
      "\n",
      "ðŸš€ Batch 1700â€“1799\n",
      "âŒ [1742] JSON error after fix: Invalid \\escape: line 10 column 148 (char 849)\n",
      "âŒ [1749] JSON error after fix: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ðŸ”„ Processing Batches:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [3:26:17<2:46:36, 833.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch 1700â€“1799 saved to reddit_nlp_features\n",
      "ðŸ“ Checkpoint updated.\n",
      "â±ï¸ Duration: 878.35 seconds\n",
      "\n",
      "ðŸš€ Batch 1800â€“1899\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Config ---\n",
    "BATCH_SIZE = 100\n",
    "TABLE_NAME = \"reddit_nlp_features\"\n",
    "DRIVE_SUBFOLDER = \"/content/drive/MyDrive/reddit_data\"\n",
    "DRIVE_DB_FILE = os.path.join(DRIVE_SUBFOLDER, \"reddit_progress.duckdb\")\n",
    "CHECKPOINT_FILE = \"checkpoint.txt\"\n",
    "\n",
    "# --- Ensure Drive is mounted ---\n",
    "assert os.path.exists(DRIVE_SUBFOLDER), \"Google Drive folder not found. Please mount Drive first.\"\n",
    "\n",
    "# --- Connect to DuckDB directly in Drive ---\n",
    "conn = duckdb.connect(DRIVE_DB_FILE)\n",
    "\n",
    "# --- Fetch schema if table exists ---\n",
    "try:\n",
    "    table_cols = [col[1] for col in conn.execute(f\"PRAGMA table_info({TABLE_NAME})\").fetchall()]\n",
    "except:\n",
    "    table_cols = []\n",
    "\n",
    "# --- Resume from checkpoint or fallback to 300 ---\n",
    "fallback_start = 300\n",
    "\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "        checkpoint_val = int(f.read().strip())\n",
    "        start_index = max(checkpoint_val, fallback_start)\n",
    "    print(f\"â© Resuming from checkpoint at row {start_index}\")\n",
    "else:\n",
    "    start_index = fallback_start\n",
    "    print(f\"â© No checkpoint found. Starting from row {start_index}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Track failures ---\n",
    "failed_rows = []\n",
    "\n",
    "# --- Main Batch Loop ---\n",
    "for start_idx in tqdm(range(start_index, len(df_loaded), BATCH_SIZE), desc=\"ðŸ”„ Processing Batches\"):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, len(df_loaded))\n",
    "    print(f\"\\nðŸš€ Batch {start_idx}â€“{end_idx - 1}\")\n",
    "    batch_start_time = datetime.now()\n",
    "\n",
    "    batch = df_loaded.iloc[start_idx:end_idx]\n",
    "    combined_rows = []\n",
    "\n",
    "    for idx, row in batch.iterrows():\n",
    "        try:\n",
    "            text = str(row.get(\"full_text\", \"\"))[:1800]\n",
    "            row_meta = row.drop(labels=[\"full_text\"]).to_dict()\n",
    "\n",
    "            # --- Run models ---\n",
    "            parsed = safe_generate_and_parse(input_text=text, tokenizer=llm_tokenizer, model=llm_model, template=TEMPLATE, row_id=idx)\n",
    "            emotion = get_emotion_vector(text=text, tokenizer=emotion_tokenizer, model=emotion_model, labels=emotion_labels, device=device)\n",
    "\n",
    "            if parsed[\"success\"] and emotion[\"success\"]:\n",
    "                combined = {\n",
    "                    **row_meta,\n",
    "                    **parsed[\"data\"],\n",
    "                    **emotion[\"data\"],\n",
    "                    \"row_index\": idx,\n",
    "                    \"text\": text\n",
    "                }\n",
    "\n",
    "                # Flatten lists\n",
    "                for k, v in combined.items():\n",
    "                    if hasattr(v, \"tolist\"):\n",
    "                        v = v.tolist()\n",
    "                    if isinstance(v, list) and all(isinstance(i, str) for i in v):\n",
    "                        combined[k] = \"; \".join(v)\n",
    "                    else:\n",
    "                        combined[k] = v\n",
    "\n",
    "                combined_rows.append(combined)\n",
    "            else:\n",
    "                failed_rows.append({\n",
    "                    \"row_index\": idx,\n",
    "                    \"error\": parsed.get(\"error\") or emotion.get(\"error\"),\n",
    "                    \"text\": text[:300]\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_rows.append({\n",
    "                \"row_index\": idx,\n",
    "                \"error\": str(e),\n",
    "                \"text\": text[:300]\n",
    "            })\n",
    "\n",
    "    # --- Save batch to DuckDB ---\n",
    "    if combined_rows:\n",
    "        df_combined = pd.DataFrame(combined_rows)\n",
    "\n",
    "        if table_cols:\n",
    "            df_combined = df_combined[[col for col in df_combined.columns if col in table_cols]]\n",
    "        else:\n",
    "            table_cols = df_combined.columns.tolist()\n",
    "            conn.execute(f\"CREATE TABLE IF NOT EXISTS {TABLE_NAME} AS SELECT * FROM df_combined LIMIT 0\")\n",
    "\n",
    "        conn.execute(f\"INSERT INTO {TABLE_NAME} SELECT * FROM df_combined\")\n",
    "        print(f\"âœ… Batch {start_idx}â€“{end_idx - 1} saved to {TABLE_NAME}\")\n",
    "\n",
    "        # --- Save checkpoint (start of this batch for retry safety) ---\n",
    "        with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "            f.write(str(start_idx))\n",
    "        print(\"ðŸ“ Checkpoint updated.\")\n",
    "\n",
    "        # --- Duration log ---\n",
    "        duration = (datetime.now() - batch_start_time).total_seconds()\n",
    "        print(f\"â±ï¸ Duration: {round(duration, 2)} seconds\")\n",
    "\n",
    "# --- Close DB connection ---\n",
    "conn.close()\n",
    "\n",
    "# --- Save failures if any ---\n",
    "if failed_rows:\n",
    "    pd.DataFrame(failed_rows).to_csv(\"failed_rows.csv\", index=False)\n",
    "    print(f\"âš ï¸ {len(failed_rows)} failed rows logged to failed_rows.csv\")\n",
    "\n",
    "print(f\"\\nðŸ Done! All processed data written to {TABLE_NAME} in Google Drive DuckDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAtPZq-TYLx1",
    "outputId": "8235df1b-47ee-4d30-b50a-b1768daa499e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.6M\n",
      "-rw------- 1 root root 5.1M Jun  5 08:32 reddit_20250605_083205.duckdb\n",
      "-rw------- 1 root root  12K Jun  8 11:06 reddit_progress.duckdb\n",
      "-rw------- 1 root root 573K Jun  8 11:48 reddit_progress.duckdb.wal\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"/content/drive/MyDrive/reddit_data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaUumeeWwho2"
   },
   "source": [
    "## Section 4. Reload Reddit Scraped Results from Colab## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "odIlzOeT_ceU",
    "outputId": "16dc2a40-a3ab-4052-8fd5-bace351896ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Tables found: [('reddit_nlp_features',)]\n",
      "âœ… Loaded 1 rows from table 'reddit_nlp_features'\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-75ffccb8-5d96-410b-98f0-3bc642843258\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>matched_terms</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_depth</th>\n",
       "      <th>summary</th>\n",
       "      <th>pain_points</th>\n",
       "      <th>emotion_phrases</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographic_proximity</th>\n",
       "      <th>demographic_evidence_phrases</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>row_index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post</td>\n",
       "      <td>Meditation</td>\n",
       "      <td>Anima_Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>Equanimity and Non-Attachment Meditation, A Novel Approach</td>\n",
       "      <td>[act]</td>\n",
       "      <td>https://reddit.com/r/Meditation/comments/1l3o2jc/equanimity_and_nonattachment_meditation_a_novel/</td>\n",
       "      <td>2025-06-05T02:27:44</td>\n",
       "      <td>Sharing / Insight ðŸ’¡</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1l3o2jc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The user developed a meditation practice using phrases for equanimity and non-attachment. The practice involves mentally saying the phrases while breathing naturally and syncing it to the breathing. The goal is to achieve a natural sense of equanimity and non-attachment.</td>\n",
       "      <td>none</td>\n",
       "      <td>fine</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.57</td>\n",
       "      <td>positive</td>\n",
       "      <td>meditation practice; equanimity; non-attachment</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "      <td>0.430545</td>\n",
       "      <td>0.167192</td>\n",
       "      <td>0.182123</td>\n",
       "      <td>0.278183</td>\n",
       "      <td>0.653991</td>\n",
       "      <td>0.916768</td>\n",
       "      <td>0.486951</td>\n",
       "      <td>0.643949</td>\n",
       "      <td>0.64548</td>\n",
       "      <td>0.236684</td>\n",
       "      <td>0.442498</td>\n",
       "      <td>0.225125</td>\n",
       "      <td>0.265867</td>\n",
       "      <td>0.268055</td>\n",
       "      <td>0.285222</td>\n",
       "      <td>0.455119</td>\n",
       "      <td>0.294263</td>\n",
       "      <td>0.363282</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.247318</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>0.255882</td>\n",
       "      <td>0.692624</td>\n",
       "      <td>0.653467</td>\n",
       "      <td>0.410916</td>\n",
       "      <td>0.32566</td>\n",
       "      <td>0.338183</td>\n",
       "      <td>0.759731</td>\n",
       "      <td>0</td>\n",
       "      <td>This practice uses phrases for equanimity and non-attachment in a similar way to the ones for popular forms of metta bhavana (loving kindness) meditation.\\n\\nI developed this specific form that I am sharing here myself and am being transparent about this, so you can see it as a novel approach. Popular metta practice has phrases that one repeats as part of the process, such as 'may all beings be well'. Below are phrases for equanimity and non-attachment. This is just a possible way to approach it, one way to put the mind in the mode of equanimity and non-attachment, so that this state can then be abided in directly. You can try it out if you are interested. I am just passing on something which has been helpful for me as perhaps it may help others too.\\n\\nYou can mentally say the phrases, with the first part of each phrase being on the in-breath, and the second part (the 'fine') being on the out-breath. Doing this while breathing naturally, meaning not deliberately controlling the breath. Try it with eyes closed, and then if you wish, you can experiment with eyes open on some occasions to integrate it into the sense experience and make it gradually more available 'off the mat'.\\n\\nSo mentally saying these phrases while in the relative stillness and safety of a meditation posture, either sitting or lying down, and syncing it to the breathing:\\n\\n\"If it comes ... fine\\n\\nIf it doesn't come ... fine\\n\\nIf it changes ... fine\\n\\nIf it doesn't change ... fine\\n\\nIf it goes ... fine\\n\\nIf it doesn't go ... fine\"\\n\\nYou meditate like this until there is a natural sense of equanimity and non-attachment, a natural letting go into that, which might occur after only doing it once through, or it might take a bit longer with more repetitions. It puts the mind closer in attitude to the nature unconditiona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75ffccb8-5d96-410b-98f0-3bc642843258')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-75ffccb8-5d96-410b-98f0-3bc642843258 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-75ffccb8-5d96-410b-98f0-3bc642843258');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   type   subreddit        author  score  \\\n",
       "0  post  Meditation  Anima_Monday      2   \n",
       "\n",
       "                                                        title matched_terms  \\\n",
       "0  Equanimity and Non-Attachment Meditation, A Novel Approach         [act]   \n",
       "\n",
       "                                                                                                 url  \\\n",
       "0  https://reddit.com/r/Meditation/comments/1l3o2jc/equanimity_and_nonattachment_meditation_a_novel/   \n",
       "\n",
       "           created_utc      link_flair_text  num_comments       id  \\\n",
       "0  2025-06-05T02:27:44  Sharing / Insight ðŸ’¡           0.0  1l3o2jc   \n",
       "\n",
       "   comment_depth  \\\n",
       "0            NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           summary  \\\n",
       "0  The user developed a meditation practice using phrases for equanimity and non-attachment. The practice involves mentally saying the phrases while breathing naturally and syncing it to the breathing. The goal is to achieve a natural sense of equanimity and non-attachment.   \n",
       "\n",
       "  pain_points emotion_phrases emotion_label  sentiment_score sentiment  \\\n",
       "0        none            fine          calm             0.57  positive   \n",
       "\n",
       "                                            themes demographic_proximity  \\\n",
       "0  meditation practice; equanimity; non-attachment               unknown   \n",
       "\n",
       "  demographic_evidence_phrases  admiration  amusement     anger  annoyance  \\\n",
       "0                         none    0.430545   0.167192  0.182123   0.278183   \n",
       "\n",
       "   approval    caring  confusion  curiosity   desire  disappointment  \\\n",
       "0  0.653991  0.916768   0.486951   0.643949  0.64548        0.236684   \n",
       "\n",
       "   disapproval   disgust  embarrassment  excitement      fear  gratitude  \\\n",
       "0     0.442498  0.225125       0.265867    0.268055  0.285222   0.455119   \n",
       "\n",
       "      grief       joy      love  nervousness  optimism     pride  realization  \\\n",
       "0  0.294263  0.363282  0.502222     0.247318  0.316201  0.255882     0.692624   \n",
       "\n",
       "     relief   remorse  sadness  surprise   neutral  row_index  \\\n",
       "0  0.653467  0.410916  0.32566  0.338183  0.759731          0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \n",
       "0  This practice uses phrases for equanimity and non-attachment in a similar way to the ones for popular forms of metta bhavana (loving kindness) meditation.\\n\\nI developed this specific form that I am sharing here myself and am being transparent about this, so you can see it as a novel approach. Popular metta practice has phrases that one repeats as part of the process, such as 'may all beings be well'. Below are phrases for equanimity and non-attachment. This is just a possible way to approach it, one way to put the mind in the mode of equanimity and non-attachment, so that this state can then be abided in directly. You can try it out if you are interested. I am just passing on something which has been helpful for me as perhaps it may help others too.\\n\\nYou can mentally say the phrases, with the first part of each phrase being on the in-breath, and the second part (the 'fine') being on the out-breath. Doing this while breathing naturally, meaning not deliberately controlling the breath. Try it with eyes closed, and then if you wish, you can experiment with eyes open on some occasions to integrate it into the sense experience and make it gradually more available 'off the mat'.\\n\\nSo mentally saying these phrases while in the relative stillness and safety of a meditation posture, either sitting or lying down, and syncing it to the breathing:\\n\\n\"If it comes ... fine\\n\\nIf it doesn't come ... fine\\n\\nIf it changes ... fine\\n\\nIf it doesn't change ... fine\\n\\nIf it goes ... fine\\n\\nIf it doesn't go ... fine\"\\n\\nYou meditate like this until there is a natural sense of equanimity and non-attachment, a natural letting go into that, which might occur after only doing it once through, or it might take a bit longer with more repetitions. It puts the mind closer in attitude to the nature unconditiona  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# --- Config ---\n",
    "TABLE_NAME = \"reddit_nlp_features\"\n",
    "LOCAL_DB_FILE = \"reddit_progress.duckdb\"\n",
    "DRIVE_SUBFOLDER = \"/content/drive/MyDrive/reddit_data\"\n",
    "DRIVE_DB_FILE = os.path.join(DRIVE_SUBFOLDER, LOCAL_DB_FILE)\n",
    "\n",
    "DRIVE_DB_FILE = os.path.join(DRIVE_SUBFOLDER, LOCAL_DB_FILE)\n",
    "# --- Mount Google Drive (if not already) ---\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# --- Connect to DB file in Drive ---\n",
    "conn = duckdb.connect(DRIVE_DB_FILE)\n",
    "\n",
    "# --- List tables ---\n",
    "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "print(\"ðŸ“‹ Tables found:\", tables)\n",
    "\n",
    "# --- Check if target table exists ---\n",
    "if (TABLE_NAME,) in tables:\n",
    "    df_reddit = conn.execute(f\"SELECT * FROM {TABLE_NAME}\").df()\n",
    "    print(f\"âœ… Loaded {len(df_reddit)} rows from table '{TABLE_NAME}'\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(df_reddit.head())\n",
    "else:\n",
    "    print(f\"âŒ Table '{TABLE_NAME}' not found in the database.\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uYTZNyb_czN"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vszSIANnwiqe",
    "outputId": "0925f933-78ed-40c6-de95-10810e995c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "ðŸ“‹ Tables found: []\n",
      "âŒ Table 'reddit_nlp_features' not found in the database.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7mNodA1Cfsk"
   },
   "outputs": [],
   "source": [
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38DXVUsYrO33"
   },
   "source": [
    "## Section 5. Cluster Analysis## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-XvBVketyBC"
   },
   "source": [
    "## BACKUP Section 3. LLMs NLP(Alternative-Gemma 2)## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D7IxXeLuzoM"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "\n",
    "from google.colab import userdata\n",
    "hf_token = userdata.get('HuggingFace')\n",
    "\n",
    "if hf_token is None:\n",
    "    raise ValueError(\"ðŸ” Hugging Face token not found. Please add it to Colab secrets under 'HF_TOKEN'.\")\n",
    "\n",
    "# Authenticate with Hugging Face Hub\n",
    "login(token=hf_token)\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513,
     "referenced_widgets": [
      "2490046b895849168594773ffa61bd1c",
      "913ec19d98e04ff28d3c490fa65b904f",
      "c2ff25826e0e4bd69d36ac96182a09fb",
      "25861f636d9d439ca081bd0bff5077aa",
      "8b0002f1042b4ee68b967effbf4d7788",
      "b92b19760980443185289a707d4b1ec8",
      "06c9a36eaf604c8a947830c695bef19d",
      "6e111bfbc5d047ab99e59d3a1476a9e6",
      "f31a9b1eab8a4b53a16e0d3738d542b4",
      "1f8707ce833341b092b44538896502d8",
      "6d8d80cfbe6943e586545f8ff205489c"
     ]
    },
    "collapsed": true,
    "id": "oWM4-r-0_khm",
    "outputId": "0b17776c-28a4-462d-a443-8ad9d4260082"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2490046b895849168594773ffa61bd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm()\n",
       "        (post_attention_layernorm): GemmaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# === HuggingFace Model ID ===\n",
    "model_id = \"google/gemma-2b-it\"  # or your preferred size like \"gemma-7b-it\"\n",
    "\n",
    "# === Load Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # ensures padding is valid\n",
    "\n",
    "# === Load Model (FP16, no quantization) ===\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    token=hf_token\n",
    ")\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
